
import { GoogleGenAI } from "@google/genai";
import { Product } from "./types";

export const generateTryOn = async (
  base64UserImage: string,
  selectedProducts: Product[]
): Promise<string> => {
  // Fix: Initialized GoogleGenAI with a direct reference to process.env.API_KEY as per guidelines
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  
  // Combine fragments into a coherent fashion prompt
  const fragments = selectedProducts.map(p => p.promptFragment).join(", ");
  const prompt = `Perform high-fashion virtual try-on in-painting. 
  Maintain the person's face, original hair, skin tone, pose, and the background exactly as they are.
  Replace the clothing the person is currently wearing with the following items: ${fragments}.
  Ensure the clothing fits naturally to the body's pose and lighting. 
  The final result should look like a professional high-end studio photograph.
  Only return the edited image.`;

  const userImagePart = {
    inlineData: {
      mimeType: "image/png",
      data: base64UserImage.split(",")[1], // Strip data:image/png;base64,
    },
  };

  const textPart = {
    text: prompt,
  };

  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-image",
      contents: { parts: [userImagePart, textPart] },
    });

    let generatedImageUrl = "";
    
    // Fix: Iterating through parts to find the inlineData part containing the generated image
    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        const base64EncodeString = part.inlineData.data;
        generatedImageUrl = `data:image/png;base64,${base64EncodeString}`;
        break;
      }
    }

    if (!generatedImageUrl) {
      throw new Error("No image was generated by the model.");
    }

    return generatedImageUrl;
  } catch (error) {
    console.error("Gemini Error:", error);
    throw error;
  }
};
